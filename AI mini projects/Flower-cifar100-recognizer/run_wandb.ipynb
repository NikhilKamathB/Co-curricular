{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL experiment tracking using Wandb.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries.\n",
    "# Importing libraries.\n",
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from trainer.misc import net, data, train, test, utils, config\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 -  Wandb personal account - Flower recognizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the environment variables so as to  access personal Wandb account.\n",
    "os.environ[\"WANDB_BASE_URL\"] = os.getenv(\"WANDB_BASE_URL\", '')\n",
    "os.environ[\"WANDB_API_KEY\"] = os.getenv(\"WANDB_API_KEY\", '')\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = os.getenv(\"WANDB_NOTEBOOK_NAME\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login into Wandb.\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define attributes makeup for flower dataset.\n",
    "def make(config):\n",
    "    os.environ['TORCH_HOME'] = config.model_dir\n",
    "    DEVICE = torch.device(config.device)\n",
    "    _data = data.Data(data_dir=config.data_dir, train_batch_size=config.train_batch_size, test_batch_size=config.test_batch_size)\n",
    "    TRAIN_LOADER, TEST_LOADER = _data.get_loaders()\n",
    "    MODEL = net.Resnet18().get_model(num_classes=config.num_classes).to(DEVICE)\n",
    "    OPTIMIZER = torch.optim.SGD(MODEL.parameters(), lr=config.lr, momentum=config.momentum)\n",
    "    CRITERION = torch.nn.CrossEntropyLoss()\n",
    "    SCHEDULER = torch.optim.lr_scheduler.ReduceLROnPlateau(OPTIMIZER, 'min', patience=config.patience)\n",
    "    return MODEL, TRAIN_LOADER, TEST_LOADER, OPTIMIZER, CRITERION, SCHEDULER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model. \n",
    "def train_model(model=None, train_loader=None, optimizer=None, criterion=None, scheduler=None, epochs=None, device=None, save_path_dir=None, verbose=None, verbose_step=None, wandb_needed=True):\n",
    "    train_loss, saved_path = train.Train(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        scheduler=scheduler,\n",
    "        epochs=epochs,\n",
    "        device=device,\n",
    "        save_path_dir=save_path_dir,\n",
    "        verbose=verbose,\n",
    "        verbose_step=verbose_step,\n",
    "        wandb_needed=wandb_needed\n",
    "    ).train()\n",
    "    return train_loss, saved_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model.\n",
    "def test_model(model=None, test_loader=None, device=None, save_path=None, test_run=None, config_save_model_path=None, wandb_needed=True):\n",
    "    image_set, label_set, pred_set, model = test.Test(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        device=device,\n",
    "        save_path=save_path,\n",
    "        test_run=test_run,\n",
    "        wandb_needed=wandb_needed\n",
    "    ).test(config_save_model_path=config_save_model_path)\n",
    "    utils.plot_output(image_set, label_set, pred_set, wandb_needed=True, wandb_title=\"Model Inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model pipeline for flower dataset.\n",
    "def model_pipeline(config=None):\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    # Initialize wandb to get started.\n",
    "    with wandb.init(project=os.getenv(\"PROJECT_NAME_1\", ''), config=config, name=f\"flower_classification_run_{TIMESTAMP}\"):\n",
    "        config = wandb.config\n",
    "        MODEL, TRAIN_LOADER, TEST_LOADER, OPTIMIZER, CRITERION, SCHEDULER = make(config)\n",
    "        _, save_path = train_model(model=MODEL, train_loader=TRAIN_LOADER, optimizer=OPTIMIZER, criterion=CRITERION, scheduler=SCHEDULER, epochs=config.epochs, device=config.device, save_path_dir=config.save_path_dir, verbose=config.verbose, verbose_step=config.verbose_step)\n",
    "        model_name = save_path.split('/')[-1]\n",
    "        onnx_name = model_name.split('.')[0]\n",
    "        test_model(model=MODEL, test_loader=TEST_LOADER, device=config.device, save_path=save_path, test_run=config.test_run, config_save_model_path=config.save_path_dir + onnx_name + \".onnx\")\n",
    "    return MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the pipeline.\n",
    "__model__ = model_pipeline(config=config.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 -  Wandb personal account - CIFAR100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "      'name': 'Training Loss',\n",
    "      'goal': 'minimize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "        'batch_size': {\n",
    "            'values': [64, 32]\n",
    "        },\n",
    "        'lr': {\n",
    "            'values': [1, 1e-1, 1e-2, 1e-3, 1e-4]\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyperparameter tuning pipeline.\n",
    "def train_hyperparameter_tuning(config=None):\n",
    "\n",
    "  # Defining attributes makeup.\n",
    "  def make(config, custom_config):\n",
    "    os.environ['TORCH_HOME'] = config.model_dir\n",
    "    DEVICE = torch.device(config.device)\n",
    "    _data = data.Data(resize=32, data_dir_cifar100=config.data_dir_cifar100, train_batch_size=custom_config.batch_size, test_batch_size=custom_config.batch_size, is_cifar100=True)\n",
    "    TRAIN_LOADER, TEST_LOADER = _data.get_loaders()\n",
    "    MODEL = net.Resnet18().get_model(num_classes=config.num_classes_cifar100).to(DEVICE)\n",
    "    OPTIMIZER = torch.optim.SGD(MODEL.parameters(), lr=custom_config.lr, momentum=config.momentum)\n",
    "    CRITERION = torch.nn.CrossEntropyLoss()\n",
    "    SCHEDULER = torch.optim.lr_scheduler.ReduceLROnPlateau(OPTIMIZER, 'min', patience=config.patience)\n",
    "    return MODEL, TRAIN_LOADER, TEST_LOADER, OPTIMIZER, CRITERION, SCHEDULER\n",
    "  # Train the model. \n",
    "  def train_model(model=None, train_loader=None, optimizer=None, criterion=None, scheduler=None, epochs=None, device=None, save_path_dir=None, model_name=None, verbose=None, verbose_step=None, wandb_needed=True):\n",
    "    train_loss, saved_path = train.Train(\n",
    "          model=model,\n",
    "          train_loader=train_loader,\n",
    "          optimizer=optimizer,\n",
    "          criterion=criterion,\n",
    "          scheduler=scheduler,\n",
    "          epochs=epochs,\n",
    "          device=device,\n",
    "          save_path_dir=save_path_dir,\n",
    "          model_name=model_name,\n",
    "          verbose=verbose,\n",
    "          verbose_step=verbose_step,\n",
    "          wandb_needed=wandb_needed\n",
    "      ).train()\n",
    "    return train_loss, saved_path\n",
    "  # Test the model.\n",
    "  def test_model(model=None, test_loader=None, device=None, save_path=None, test_run=None, config_save_model_path=None, wandb_needed=True):\n",
    "    image_set, label_set, pred_set, model = test.Test(\n",
    "        model=model,\n",
    "        test_loader=test_loader,\n",
    "        device=device,\n",
    "        save_path=save_path,\n",
    "        test_run=test_run,\n",
    "        wandb_needed=wandb_needed\n",
    "      ).test(config_save_model_path=config_save_model_path)\n",
    "    utils.plot_output(image_set, label_set, pred_set, wandb_needed=True, wandb_title=\"Model Inference\")\n",
    "  # Define model pipeline for CIFAR100.\n",
    "  def model_pipeline(actual_config=None):\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    # Initialize wandb to get started.\n",
    "    with wandb.init(project=os.getenv(\"PROJECT_NAME_2\", ''), config=actual_config, name=f\"cifar100_run_{TIMESTAMP}\"):\n",
    "        config = wandb.config\n",
    "        print(f\"Training with configuration -> {config}\")\n",
    "        MODEL, TRAIN_LOADER, TEST_LOADER, OPTIMIZER, CRITERION, SCHEDULER = make(actual_config, config)\n",
    "        _, save_path = train_model(model=MODEL, train_loader=TRAIN_LOADER, optimizer=OPTIMIZER, criterion=CRITERION, scheduler=SCHEDULER, epochs=actual_config.epochs, device=actual_config.device, save_path_dir=actual_config.save_path_dir, model_name=f\"cifar100_run_experiment_{TIMESTAMP}_\", verbose=actual_config.verbose, verbose_step=actual_config.verbose_step)\n",
    "        model_name = save_path.split('/')[-1]\n",
    "        onnx_name = model_name.split('.')[0]\n",
    "        test_model(model=MODEL, test_loader=TEST_LOADER, device=config.device, save_path=save_path, test_run=config.test_run, config_save_model_path=config.save_path_dir + onnx_name + \".onnx\")\n",
    "    return MODEL\n",
    "  \n",
    "  _ = model_pipeline(actual_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define attributes makeup for CIFAR100.\n",
    "sweep_id = wandb.sweep(sweep_config, project=os.getenv(\"PROJECT_NAME_2\", ''))\n",
    "wandb.agent(sweep_id, train_hyperparameter_tuning(config.config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f9968ebedc9844ea242576b603ca490550240534f3c5f301aa09b66efd73274"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('ai': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}